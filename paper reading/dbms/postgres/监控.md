## PostgreSQL监控

> 参考《PostgreSQL监控实战——基于Pigsty解决实际监控问题》

1.  根据Google的[SRE](https://github.com/captn3m0/google-sre-ebook)(Site Reliability Engineering)，监控指标可分为四类：

   - **饱和度** 

     给定资源的使用量。

     - 基础：
       - 基础资源使用率
       - 打开的文件句柄数
       - TCP连接数
     - 业务：
       - 核心功能使用率
       - 集群数据均衡度
       - 队列长度

   - **延迟**

     衡量完成操作所需时间。

     - 基础：
       - IO wait
       - 网络延迟
     - 业务：
       - 核心功能延迟
       - 集群数据同步延迟

   - **流量**

     衡量组件和系统的“繁忙程度”。

     - 基础：
       - 磁盘流量
       - 网卡流量
     - 业务：
       - 核心功能请求速率

   - **错误**

     了解组件的运行状况、未能正确地响应请求的频率。

     - 基础：
       - 宕机
       - 进程存活
     - 业务：
       - 核心功能错误
       - 基础数据丢失
       - 可用实例数占比
       - 上游依赖错误
       - 日志错误

2. pigsty重要的监控指标：

   1. **数据库负载** Load

      衡量了数据库的负载程度，定义为：活跃事务时长占CPU总可用时间的比例（类比了CPU的利用率）。 Load在0~40%之间为低负载，40%~70%为中负载，70%以上就为高负载。

      那么为什么Load采取了这个指标，而不是其他的定义？[官方文档](https://pigsty.cc/zh/blog/2020/05/29/postgresql%E7%9A%84kpi/)给出了如下解释：

      如果使用CPU或IO等机器指标的话，它们确实一定程度可以反映数据库的负载；但如果瓶颈在数据库系统自身上，比如锁冲突之类的，此时底层的硬件资源利用率 就难以衡量数据库本身的饱和度了。

      如果使用QPS、TPS等流量指标，是很难进行横向比较的，因为简单的查询与复杂的查询都只会算作一个Query。

      对于RT这种延迟指标，也是比较有参考价值的，因为理论上Load越大，平均的响应时间肯定会越长，但是它也只能定性的指出系统的负载变化趋势，不能定量地给出负载到底多大。

   2. **数据库饱和度** Saturation

      衡量了数据库整体资源利用率。这里考虑的是数据库如果是非独占式部署，其他应用也会占用CPU资源，此时就应该取Load和CPU利用率二者的最大值 来衡量整体的资源利用率。

      那么饱和度一个很大的作用就是 进行**水位的评估**（可以根据<u>业务的周期性</u>，来选择过去一周/一月的水位情况），从而看是否需要扩缩容、调整配置等。

   3. **主从复制延迟**

   4. **查询响应时间（平均）**Query RT

   5. **活跃的后端进程数**

   6. **年龄**

   7. **CPU使用率**

   8. **每秒查询数 QPS**

   9. **连接池排队**

   10. **错误日志数**

3. 对于应用程序来说，QPS和RT是最关注的指标；对于DBA来说，饱和度是最关注的指标。

4. 监控数据的来源：

   - **数据库**（包括Pg本身的监控、系统目录信息、日志中的统计信息）
   - **中间件**
   - **操作系统**
   - **负载均衡器**（如HAproxy的监控指标）

5. 如何针对操作系统内核进行参数调优？——可参考tuned调参工具（CentOS）。

6. 对于常用的通用监控方案还有：[zabbix](https://www.zabbix.com/)和[Prometheus](https://prometheus.io/)，可以进一步了解。