1. SIMD(Single Instruction, Multiple Data): 单指令多数据流(一条指令操作多个数据)

   - 是一种指令集，允许CPU同时在多个数据上进行操作

   - 帮助CPU实现数据并行，提高运算效率

   - 以加法指令为例，单指令单数据（SISD）的CPU对加法指令译码后，执行部件先访问内存，取得第一个操作数；之后再一次访问内存，取得第二个操作数；随后才能进行求和运算。

   - 而在SIMD型的CPU中，指令译码后几个执行部件**同时访问内存**，**一次性获得所有操作数进行运算**。这个特点使SIMD特别适合于多媒体应用等数据密集型运算。

   - 例如：

     ```
     X := {8,7,6,5,4,3,2,1}
     Y := {1,1,1,1,1,1,1,1}
     for i:=0; i<n; i++ {
     	Z[i] = X[i] + Y[i]
     }
     ```

     - 在SISD中，得先计算8+1=9，然后Z[0]=9；以此类推，需要执行8条加法指令
     - 在SIMD中，(假设SIMD寄存器大小为128-bit，int为32位，则**reg中可存放4个整型**)，则可以先计算[8,7,6,5]+[1,1,1,1]=[9,8,7,6]；再计算[4,3,2,1]+[1,1,1,1]=[5,4,3,2]，一共只用两条加法指令。

   - 优点：当算法为**向量化算法(vectorized)**时，性能和资源利用有明显提升。

   - 缺点：

     - 适用于SIMD的算法通常需要手动实现
     - 可能对数据对齐有约束
     - 收集数据放入SIMD reg中，然后再把它们分到正确的位置比较麻烦

2. Parallel Sort-Merge Join(排序-合并): R ⨝ S

      1. Partition阶段: 对关系R进行划分，并分配给不同的核心
      2. Sort阶段: **基于join key**对R和S中的元组进行**排序**
         - 开销最大的环节：尽量利用多核；可以的话使用SIMD指令
         - Cache-Conscious sorting:
           1. In-Register: 排序的每一趟与CPU寄存器大小吻合
           2. In-Cache: 把上一步的输出合并，使得与cache大小吻合(重复合并，直到每一趟为cache的1/2)
           3. Out-of-Cache: 每一趟超出高速缓存大小，即继续**在内存中排序**
      3. Merge阶段: 扫描排序好的的关系，并比较元组。(外层关系R只需要扫描一次)

3. Sorting Network: 排序网络——In-Register

   - 高效：很少的数据依赖 以及 没有分支。

   - 通过互联线路(wires)来排序：![](https://s2.ax1x.com/2019/09/13/nryhcj.md.png)

     对于4个数据排序，总共只需要10条指令![nryOCF.png](https://s2.ax1x.com/2019/09/13/nryOCF.png)

     对于多个寄存器：![](https://s2.ax1x.com/2019/09/13/nr6kCD.md.png)

     为什么不能直接在一个寄存器内排序？——单个排序网络中的数据都来自不同寄存器，可通过SIMD来加速排序；**这里4个寄存器可视为4个SIMD向量**

4. Bitonic Merge Network: 双调合并网络——In-Cache
   - 由于有SIMD，缓存内排序使用**多级二路归并**: 每一次把两个有序的数组，合并为一个**全局有序**的数组

5. Multi-Way Merging: 多路合并——Out-of-Cache
   - 比起二路归并，**减少了内存读写**
   - 每次排序块能填满CPU缓存，避免频繁切换任务的开销

6. 想起上一节的基于Hash的连接，hash得到结果会随机访问内存，引起缓存命中率低的问题(如果hash table大于cache，几乎每次访问都会造成cahce miss)——通过**partition**的hash join
7. Merge阶段：多核情况下，若有各自的输出缓冲区，可以不需要同步并行完成
8. Sort-Merge的变种：
   - Multi-Way
   - Multi-Pass
   - Massively Parallel

9. 并行的几大规则：可参考**《并行算法设计与性能优化》**
   - 不要随机写非局部性内存——对数据分块，重新分配，使得每个核心在局部数据上进行工作
   - 对于非局部性内存只进行**顺序读**操作——允许硬件**预取(prefetch)**来掩盖传输延迟（如果程序的局部性不好，则硬件预取反而会降低性能；故**要顺序地读，而不是随机读**）
   - 一个核心不应该等待其他核心